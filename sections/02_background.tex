\subsection{Optimizing Laser Systems}
Traditionally, HPL systems' parameters have been optimized using independent 1D grid-searches over all the considered dimensions. 
While straightforward, this approach naively overlooks the joint effect varying multiple parameters simultaneously can have on the system. 
More recently, Evolution Strategies (ES)~\citep{baumert1997femtosecond, arteaga2014supercontinuum, woodward2016towards}, and Bayesian Optimization (BO)~\citep{loughran2023automated, shalloo2020automation, capuano2022laser, anjum2024high} have been proposed to optimize HPL performance. 
Differently from grid-search, ES and BO do take into account the joint effect of different parameters on the system, and proved effective in real-world experiments~\citep{shalloo2020automation}. 
However, black-box methods tend to be computationally demanding in the number of functions evaluations---in practice, real-world laser bursts. 
While BO is significantly more sample efficient than ES~\citep{capuano2022laser}, both ES and BO typically do not provide guarantees regarding the stability of the control configuration to changes in the environment.
That is, for any changes in the experimental condition one could need to re-optimize the system from scratch, just as human experts would do. 
Indeed, black-box algorithms are used to optimize an unknown objective function, and typically rely on stationarity assumptions within experimental conditions, thus overlooking the transient and complex dynamics characteristic of high-intensity phase accumulation processes in non-linear crystals.
In addition---differently from grid search---the safe implementation of black-box methods on real-world hardware can be challenging, as gains in sample efficiency might trade-off with erratic exploration of the parameter space~\citep{capuano2023temporl}, endangering system's safety.
Lastly, being inherently oriented towards finding \textit{point} solutions---control \textit{parameters} rather than control \textit{strategies}---black-box methods cannot robustly exploit approximate \textit{simulations} of \textit{real-world} HPL systems, as the objective function's landscape may differ significantly across the \textit{reality gap}~\citep{tobin2017domain}.


To allow for a more adaptive control of laser systems, recent works have investigated the application of Reinforcement Learning (RL) to HPL systems~\citep{kuprikov2022deep, rakhmatulin2024reinforcement, mareev2023self, capuano2023temporl}. 
\citet{mareev2023self} investigated the application of DRL to maintain a laser beam focused on a solid target, shifting away as a consequence of high-energy light-matter interactions and thus requiring constant target-position adjustment. 
\cite{rakhmatulin2024reinforcement} investigated the application of RL to the problem of optics alignment in laser systems, controlling the position of mirrors via real-time camera feedback. 
While both target location and mirror alignment have a significant impact on the final intensity conveyed by the beam, neither directly shapes the temporal profile of laser pulses, and thus the final peak intensity. 
\cite{kuprikov2022deep} learned a controller to adaptively adjust the power supplied to the laser, and the filters used to temporally shape the output, thus directly impacting peak intensity. 
However, the authors considered the problem of ensuring highly-similar pulses between multiple laser bursts, by learning to mode-lock the system, rather than shaping the individual pulse. 
\cite{capuano2023temporl} studies the problem of learning a controller for pulse shaping, by directly tuning the dispersion coefficients, thus ensuring a closer loop between control parameters and peak intensity. 
However, \cite{capuano2023temporl} overlook several practical aspects associated with deploying control policies to real world laser systems, such as the necessity of coping with possibly imprecise estimates of the experimental conditions, and the need to adapt to the non-stationary of the experimental environment.
Unlike previous attempts at temporal pulse shaping, we work backwards from real-world deployment requirements, extending the current research by learning a robust control policy for the dispersion coefficients that is (1) machine-safe to deploy, (2) inherently adaptive and (3) uses \textit{FROG traces}, images readily available in most HPL diagnostic systems.
Accordingly, our method is not directly comparable to black-box methods such as BO or ES because (1) black-box methods are not suited to process unstructured observations such as images, and (2) black-box methods suffer from significant limitations in transferring point solutions across the reality gap.
Lastly, we note that attempting to use the optimal control parameters obtained with black-box methods \textit{in simulation} as an initialization for efficient \textit{real-world} optimization fundamentally depends on access to high-fidelity simulations, which remain largely unavailable for most HPL systems.


\subsection{Shaping Laser Pulses}
The optimization of laser pulse shape and duration is a critical challenge in HPL systems, particularly for applications in laser-plasma acceleration, high-intensity laser-matter interactions, and inertial confinement fusion. 
Furthermore, the precise control of pulse shape directly influences the peak intensity, energy deposition efficiency, and nonlinear optical effects encountered during laser propagation. In applications of HPL systems to charged particle acceleration~\citep{grittani2020device}, directly measuring the particles' beam energy is a quantum-destructive process---charged particles lose their energy when an experimental energy probe interacts with them.
However, proxying particles' beam energy with pulse's peak intensity, HPL systems can be optimized using the peak intensity \( I^* \) produced. 
At iso-energy, intensity maximization takes place by minimizing the pulse duration, measured by its full-width half-maximum (FWHM) value---the value \( \vert t_l - t_r \vert: I(t_l)=I(t_r)= \frac 12 I^* \). Ultra-short pulses' duration is typically inferred from \emph{frequency-resolved optical gating} (FROG) traces~\citep{trebino1993using}, for the scope of this work considered as single-channel \textit{images} visualizing the spectral phase accumulated by a pulse. 
Thus, black-box methods and 1D-grid search are fundamentally ill-posed to use these proxies of particle beam's energy as input, while DRL can instead fully leverage the advancements made in Deep Learning to handle unstructured data formats as control inputs~\citep{mnih2013playing}.

In practice, HPL systems rely on the energy transfer from a high-power primary \textit{pump} laser beam to a secondary \textit{seed} laser beam. The spectral and temporal characteristics of the pump laser determine much of the achievable pulse intensity. Critically, for the sake of intensity gains in the seed laser, the pump laser is usually run through an amplification chain introducing both linear and nonlinear phase distortions. As phase regulates how the spectral intensity overlays in the time domain~\citep{paschotta2008field}, it must be carefully controlled to achieve efficient amplification at the pump and seed level. 
Typically, pump chains follow a Chirped Pulse Amplification (CPA) scheme. Figure~\ref{fig:figure1_and_cpa} illustrates the CPA process, where the initial pump pulse is (1) stretched in time to avoid nonlinear effects and damage to the earlier stages of the pump chain due to high intensities (2) amplified via regenerative and multipass amplifiers, and (3) re-compressed in time to achieve high peak intensity.

Unlike the amplification and compression stages, the process of pulse stretching can typically be controlled externally from laser specialists, varying the dispersion coefficients of the phase of the pump laser applied. The spectral phase of a laser beam \( \varphi(\omega) \) is typically modeled using a Taylor expansion around the central angular frequency of the pulse \( \omega_0$, yielding $\varphi(\omega) = \sum_{k=0}^{\infty} \frac 1{k!}\frac{\partial^k \varphi}{\partial \omega^k} (\omega - \omega_0)^k \). The first two terms in this polynomial expansion---\( \varphi(\omega) \) and \( \varphi^\prime(\omega)(\omega - \omega_0) \)---do not directly influence the shape of the pulse in the temporal domain. Conversely, second-order (\textit{group-delay dispersion}, GDD), third-order (\textit{third-order dispersion}, TOD) and fourth-order (\textit{fourth-order dispersion}, FOD) derivatives---jointly referred to in this work with \( \psi = (\text{GDD}, \text{TOD}, \text{FOD}) \in \Psi \)---do influence the resulting temporal profile. 
By opportunely tuning \( \psi \), laser specialists are able to control the temporal profile of ultra-short laser pulses. Physically, control over $\psi$ is achieved using a Chirped Fiber Bragg Grating (CFBG), consisting of an optical fiber whose grating is adjusted inducing a temperature gradient at its extremes. Consequently, it is crucial to carefully regulate the relative temperature variations to avoid demanding abrupt control adjustments over short time intervals, which could damage the fiber.

In the context of laser optimization, one might want to maximize the intensity conveyed by a laser pulse by minimizing its duration, i.e. performing \textit{temporal shaping} by controlling \( \psi \). Typically, highly trained human experts spend hours carefully varying \( \psi \) in the real world, leveraging a mix of past experience and personal expertise at the task. The shortest time duration attainable by a laser pulse is typically referred to as Transform Limited (TL), and corresponds to perfect overlay of all the different spectral components of intensity in time---as such, it has an accumulated phase equal to \( \varphi^*(\omega)=0 \). Critically, the amplification step in CPA introduces nonlinear phase components. If this was not the case, then one could retrieve TL pulses by simply applying a phase at the stretcher level that is opposite to the one defined at the compressor's, \( \varphi_s(\omega) = - \varphi_c(\omega) \). However, the non-linearity induced by the amplification step calls for a more sophisticated control over, \( \varphi_c(\omega) \). This difficulty arises from the need to balance non-linear effects in the phase accumulation process and non-stationary experimental conditions, while adhering to a sequential control approach that ensures machine safety by limiting abrupt changes in control parameters~\citep{capuano2023temporl}.

\subsection{Sim-to-real}
Even the most sample efficient of the numerical algorithms typically considered for pulse shaping varying dispersion coefficients can require hundreads of samples~\citep{capuano2022laser}, corresponding to just as many real-world laser bursts~\citep{shalloo2020automation}. Such computational demands are hard to meet in real-world systems, and are especially more troubling if one considers the instability of the solution found with respect to changes in the experimental setting. Further, BO can endanger the system by applying abrupt controls at initialization.

We can mitigate the need for expensive real-world data samples by leveraging simulated versions of the phase accumulation process, where we can easily accommodate for large number of samples, as well as safe exploration of the dispersion coefficients space, \( \Psi \). While typically not accurate enough to directly transfer point-solutions \( \psi^* \) from simulations to the real world, simulators can be used to train control policies for different environments. The problem of transferring control policies across domains is a well-studied problem in applications of RL for robotics, and the community has extensively investigated approaches to crossing the \emph{reality gap}~\citep{tobin2017domain, valassakis2020crossing}. Considering this last point, we argue the HPL setting closely resembles the challenges the community faces when transferring policies across environments. 

Transferring a control policy across diverse environments can be achieved (1) reducing the discrepancy between them~\citep{zhu2017fast} and/or (2) applying parameter randomization to improve on the robustness of the policy~\citep{peng2018sim}.
As (1) typically requires significant modeling efforts, in this work we decide to focus on (2).
One widely adopted sim-to-real method is Domain Randomization (DR), which involves varying simulator parameters within a predefined distribution during training~\citep{valassakis2020crossing} to incentivize generalization over said parameters. DR introduces additional sources of stochasticity into the environment dynamics, making policies more robust at an increased risk of sub-optimality and over-regularization~\citep{margolis2024rapid}.

Although having proved effective on robotics tasks~\citep{antonova2017reinforcement}, DR suffers from the key limitation of needing to extensively tune the distributions used in training. Automated approaches to DR propose adaptive distribution refinement over training, e.g.~by leveraging a limited set of real-world data~\cite{tiboniadrbenchmark,tiboni2023dropo}, or based on the policy's performance under a given set of dynamics parameters~\citep{akkaya2019solving}. While effective for dexterous manipulation,~\citet{akkaya2019solving} has been observed to be sample inefficient, as it biases the policy towards learning dynamics sampled from the boundaries of the current distribution~\citep{tiboni2023domain}. A more principled approach to automated DR has been recently introduced by~\citep{tiboni2023domain}, where the authors follow the principle of maximum entropy~\citep{jaynes1957information} to resolve the ambiguity in defining DR distributions. Particularly, the authors train adaptive control policies for progressively more diverse dynamics that satisfy an arbitrary performance lower bound.
Notably, the domain randomization approaches in~\citet{akkaya2019solving,tiboni2023domain} employ history-based policies to promote implicit meta-learning strategies at test time---i.e., on-line system identification.
