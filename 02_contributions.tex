\contribution{We provide initial empirical evidence that Deep Reinforcement Learning can optimize High Power Laser systems while reducing unsafe exploration compared to a representative Bayesian-Optimization baseline.}
{Previous work predominantly relied on gradientâ€“free black-box optimizers which assume stationarity and can explore the parameter space erratically. Our comparison is limited to a well-established BO variant in simulation and therefore constitutes an initial step rather than a comprehensive benchmark.}

\contribution{We learn a control policy directly from images, which are made available via widespread diagnostics devices.}
{Instead of relying on noisy and lengthy processes to obtain structured representations of the system's state, we leverage unstructured observations coming from diagnostic devices as inputs for the control policy.}

\contribution{We train control policies entirely in simulation and evaluate their robustness across a range of simulated dynamics, providing preliminary evidence of performance retention under varying parametrizations.}
{Domain Randomization is used to expose the agent to diverse operating conditions. While encouraging, these results are confined to simulation and call for further verification on real hardware and against additional baselines.}